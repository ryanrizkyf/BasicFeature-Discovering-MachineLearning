{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendahuluan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Feature Engineering adalah proses dimana kita menerapkan pengetahuan yang kita punya untuk mendapatkan informasi yang lebih dari data yang kita punya. \n",
    "# Contohnya dari KTP seseorang, \n",
    "# Anda sebenarnya dapat mendapatkan domisili pembuatan KTP, tanggal lahir, usia, dan jenis kelamin. \n",
    "# Anda dapat menggolongkan orang-orang dengan kategori yang sama untuk membuat machine learning lebih mudah membedakan ciri orang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset yang digunakan\n",
    "\n",
    "# Di pembahasan kali ini, kita menggunakan dataset titanic yang sangat terkenal dan sering digunakan. \n",
    "# Dataset ini berasal dari Kaggle, salah satu situs kompetisi machine learning. \n",
    "# Dataset ini terdiri dari 2 file, titanic_train.csv dan titanic_test.csv.\n",
    "\n",
    "# Untuk lebih mudah mengenali data ini, kita akan langsung memulai praktek untuk meng-eksplor data dengan Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library yang digunakan\n",
    "\n",
    "# Import library python biasanya dilakukan di awal sebuah projek. Library yang kita akan gunakan antara lain:\n",
    "# pandas untuk proses dataframe dan csv\n",
    "# matplotlib untuk plotting grafik\n",
    "# seaborn untuk plotting grafik\n",
    "# sklearn untuk machine learning model\n",
    "# string untuk proses string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Set dan Concat Data Frame\n",
    "\n",
    "# Dataset ini adalah dataset Titanic asli yang didapatkan dari Kaggle. \n",
    "# Berisi data dari semua orang yang ikut di dalam Kapal Titanic ratusan tahun yang lalu.\n",
    "\n",
    "# Jadi, di dalam dataset ini kita mempunyai target variable/label yaitu Survived. \n",
    "# Semua kolom/fitur lain akan digunakan untuk menentukkan apakah penumpang ini selamat/tidak dari kejadian Titanic.\n",
    "\n",
    "# Data Train digunakan untuk melatih model machine learning kita. \n",
    "# Data Test nantinya digunakan untuk menebak akurasi model kita di Kaggle.\n",
    "\n",
    "# Pada bagian ini, akan dijelakan untuk melakukan membaca data dari file csv dan melakukan concat dataframe dengan membuat sebuah fungsi.\n",
    "\n",
    "# 1. Buat Function concat_df digunakan untuk menggabungkan dua dataset/dataframe dari 2 csv menjadi satu dataframe.\n",
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "# 2. Untuk memasukkan csv ke dalam Pandas Dataframe, kita harus menggunakan pd.read_csv()\n",
    "# Data train kita masukkan ke df_train dan Data test kita masukkan ke df_test. df_all adalah gabungan dari kedua dataframe.\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "# 3. Kita dapat menamai tiap dataframe dengan memberikan \"name\" untuk masing-masing dataframe dengan cara :\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "# 4. dfs adalah list yang berisi kedua dataframe.\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penjelasan dari dataset\n",
    "\n",
    "# PassengerId adalah id pada row, maka tidak ada pengaruh terhadap target yang dicari\n",
    "# Survived adalah target yang akan diprediksi, nilai 0 = Not Survived dan nilai 1 = Survived\n",
    "# Pclass (Passenger Class) adalah kategori level sosial ekonomi penumpang dengan nilai (1, 2 atau 3):\n",
    "# 1 = Upper Class\n",
    "# 2 = Middle Class\n",
    "# 3 = Lower Class\n",
    "# Name, Sex dan Age merupakan data self-explanatory\n",
    "# SibSp adalah jumlah saudara dari penumpang\n",
    "# Parch adalah jumlah Orang Tua dan anak dari penumpang\n",
    "# Ticket adalah jumlah tiket penumpang\n",
    "# Fare adalah tarif yang di kenakan kepada penumpang\n",
    "# Cabin adalah nomor kabin penumpang\n",
    "# Embarked adalah pelabuhan pemberangkatan ada 3 pelabuhan (C, Q atau S):\n",
    "# C = Cherbourg\n",
    "# Q = Queenstown\n",
    "# S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 891\n",
      "Number of Test Examples = 418\n",
      "\n",
      "Training X Shape = (891, 12)\n",
      "Training y Shape = 891\n",
      "\n",
      "Test X Shape = (418, 11)\n",
      "Test y Shape = 418\n",
      "\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Exploring Data\n",
    "\n",
    "# Untuk mengetahui bentuk dari dataframe kita, berapa banyak row dan column yang ada di dalamnya, kita dapat menggunakan .shape.\n",
    "\n",
    "# contoh:\n",
    "# df.shape #untuk mengeluarkan array yang berisi row dan column\n",
    "# df.shape[0] #untuk mendapatkan row\n",
    "# df.shape[1] #untuk mendapatkan column\n",
    "\n",
    "# Untuk bagian [...1...] isilah untuk mendapatkan jumlah row pada dataframe df_train \n",
    "# Untuk bagian [...2...] isilah untuk mendapatkan jumlah row pada dataframe df_test \n",
    "# Untuk bagian [...3...] isilah untuk mendapatkan jumlah row dan column pada dataframe df_train\n",
    "# Untuk bagian [...4...] isilah untuk mendapatkan jumlah row pada dataframe df_train pada column Survived\n",
    "# Untuk bagian [...5...] isilah untuk mendapatkan jumlah row dan column pada dataframe df_test\n",
    "# Untuk bagian [...6...] isilah untuk mendapatkan jumlah row pada dataframe df_test\n",
    "# Untuk bagian [...7...] isilah untuk mendapatkan column yang terdapat pada df_train dengan menggunakan .columns\n",
    "# Untuk bagian [...8...] isilah untuk mendapatkan column yang terdapat pada df_test dengan menggunakan .columns\n",
    "\n",
    "print('Number of Training Examples = {}'.format(df_train.shape[0])) #1\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0])) #2\n",
    "print('Training X Shape = {}'.format(df_train.shape)) #3\n",
    "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0])) #4\n",
    "print('Test X Shape = {}'.format(df_test.shape)) #5\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0])) #6\n",
    "print(df_train.columns) #7\n",
    "print(df_test.columns) #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "5      0            330877   8.4583   NaN        Q  \n",
      "6      0             17463  51.8625   E46        S  \n",
      "7      1            349909  21.0750   NaN        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n"
     ]
    }
   ],
   "source": [
    "# Missing Value dan Contoh data\n",
    "\n",
    "# Salah satu cara untuk menemukan Missing value pada data Anda dapat menggunakan :\n",
    "# .info(memory_usage=False)\n",
    "\n",
    "# Sekarang, Anda diminta untuk mengeluarkan missing value pada dataframe df_train\n",
    "df_train.info(memory_usage=False)\n",
    "\n",
    "# Kita dapat melihat bahwa ada beberapa data yang kosong di kolom 'Embarked, 'Age', dan 'Cabin'\n",
    "\n",
    "# Untuk melihat bagian awal dari data Anda dapat menggunakan\n",
    "print(df_train.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mencari Korelasi dan Melakukan Data Cleansing Sederhana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PassengerId  Survived    Pclass       Age     SibSp     Parch      Fare\n",
      "PassengerId     1.000000  0.005007  0.035144  0.036847  0.057527  0.001652  0.012658\n",
      "Survived        0.005007  1.000000  0.338481  0.077221  0.035322  0.081629  0.257307\n",
      "Pclass          0.035144  0.338481  1.000000  0.369226  0.083081  0.018443  0.549500\n",
      "Age             0.036847  0.077221  0.369226  1.000000  0.308247  0.189119  0.096067\n",
      "SibSp           0.057527  0.035322  0.083081  0.308247  1.000000  0.414838  0.159651\n",
      "Parch           0.001652  0.081629  0.018443  0.189119  0.414838  1.000000  0.216225\n",
      "Fare            0.012658  0.257307  0.549500  0.096067  0.159651  0.216225  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Mengetahui Korelasi Fitur\n",
    "\n",
    "# Untuk mencari korelasi antar kolom pada sebuah dataframe.\n",
    "# Anda dapat menggunakan corr().abs() seperti contoh penggunaannya di bawah ini:\n",
    "# df.corr().abs()\n",
    "\n",
    "# Sekarang teman-teman diminta mencari korelasi pada df_train untuk mengisi bagian [...1...]\n",
    "df_train_corr = df_train.corr().abs() #1\n",
    "print(df_train_corr.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca hasil korelasi fitur\n",
    "\n",
    "# Pada bagian sebelumnya, Anda sudah menjalankan perintah mendapatkan korelasi.\n",
    "\n",
    "# Apabila Anda melihat table ini Anda akan mengetahui korelasi antar kolom. \n",
    "#Korelasi dapat ditentukan dengan mendekati nilai 1 untuk korelasi positive dan nilai -1 untuk korelasi terbalik.\n",
    "\n",
    "# Pada data ini dapat dilihat bahwa target variable kita Survived sangat besar korelasinya dengan Pclass dan Fare. \n",
    "# Sedangkan Age sangat berkaitan dengan Pclass, Sibling Spouse (SibSp), Parent Children (Parch).\n",
    "\n",
    "# Dapat diasumsikan bahwa kebanyakan orang yang selamat adalah orang dengan PClass atas \n",
    "# dan Tuanya umur seseorang dapat dikatakan dia akan membawa saudara/orang tua/anak/pasangan.\n",
    "\n",
    "# Dan Fare (harga) tentu saja berkaitan dengan Pclass (kelas penumpang) seorang penumpang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "PassengerId column missing values: 0\n",
      "Survived column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 177\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 0\n",
      "Cabin column missing values: 687\n",
      "Embarked column missing values: 2\n",
      "\n",
      "\n",
      "Test Set\n",
      "PassengerId column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 86\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 1\n",
      "Cabin column missing values: 327\n",
      "Embarked column missing values: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mengenali missing data dari kolom\n",
    "\n",
    "# Perhatikan Kode Program terdapat function display_missing. \n",
    "# Function tersebut digunakan untuk mengetahui jumlah missing value dari setiap kolom.\n",
    "\n",
    "# Untuk mengeluarkan hasil missing value Anda diminta untuk mengisi bagian [...1...] dengan dataframe df dan jalankan.\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "\n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df) #1\n",
    "    \n",
    "# Dari hasil tersebut ada beberapa kolom masih terdapat nilai kosong seperti age, cabin, embarked pada dataframe training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median age of Pclass 1 females: 36.0\n",
      "Median age of Pclass 1 males: 42.0\n",
      "Median age of Pclass 2 females: 28.0\n",
      "Median age of Pclass 2 males: 29.5\n",
      "Median age of Pclass 3 females: 22.0\n",
      "Median age of Pclass 3 males: 25.0\n",
      "Median age of all passengers: 28.0\n"
     ]
    }
   ],
   "source": [
    "# Mencari nilai untuk missing value\n",
    "\n",
    "# Untuk mengisi data Age yang kosong, karena kita mengetahui bahwa Umur seseorang berkaitan dengan Kelas penumpangnya. \n",
    "# Kita dapat mengisinya dengan nilai tengah umur seseorang di dalam kelas tersebut dan berdasar jenis kelaminnya.\n",
    "\n",
    "# Jadi kita lakukan groupby terhadap Jenis Kelamin dan Kelas Penumpang, \n",
    "# lalu isi nilai tersebut ke dalam missing value yang ada di dalam data kita.\n",
    "\n",
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
    "\n",
    "# Filling the missing values in Age with the medians of Sex and Pclass groups\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengisi nilai kosong\n",
    "\n",
    "# Kita juga harus mengisi nilai yang hilang untuk kolom Embarked dan Fare.\n",
    "\n",
    "# Untuk Embarked, kebanyakan orang dari Titanic berangkat dari Southampton/S. \n",
    "# Sehingga kita dapat mengisinya dengan S saja. Ini lebih baik daripada membiarkan datanya kosong.\n",
    "# Filling the missing values in Embarked with S\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n",
    "\n",
    "# Untuk Fare, kita tahu bahwa Fare sangat berkaitan dengan Kelas Penumpang, Jumlah Parent/Children, dan Jumlah Sibling/Spouse. \n",
    "# Sehingga kita dapat mengisinya dengan nilai tengah dari orang yang berada di grup tersebut.\n",
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
