{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendahuluan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Feature Engineering adalah proses dimana kita menerapkan pengetahuan yang kita punya untuk mendapatkan informasi yang lebih dari data yang kita punya. \n",
    "# Contohnya dari KTP seseorang, \n",
    "# Anda sebenarnya dapat mendapatkan domisili pembuatan KTP, tanggal lahir, usia, dan jenis kelamin. \n",
    "# Anda dapat menggolongkan orang-orang dengan kategori yang sama untuk membuat machine learning lebih mudah membedakan ciri orang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset yang digunakan\n",
    "\n",
    "# Di pembahasan kali ini, kita menggunakan dataset titanic yang sangat terkenal dan sering digunakan. \n",
    "# Dataset ini berasal dari Kaggle, salah satu situs kompetisi machine learning. \n",
    "# Dataset ini terdiri dari 2 file, titanic_train.csv dan titanic_test.csv.\n",
    "\n",
    "# Untuk lebih mudah mengenali data ini, kita akan langsung memulai praktek untuk meng-eksplor data dengan Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library yang digunakan\n",
    "\n",
    "# Import library python biasanya dilakukan di awal sebuah projek. Library yang kita akan gunakan antara lain:\n",
    "# pandas untuk proses dataframe dan csv\n",
    "# matplotlib untuk plotting grafik\n",
    "# seaborn untuk plotting grafik\n",
    "# sklearn untuk machine learning model\n",
    "# string untuk proses string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Set dan Concat Data Frame\n",
    "\n",
    "# Dataset ini adalah dataset Titanic asli yang didapatkan dari Kaggle. \n",
    "# Berisi data dari semua orang yang ikut di dalam Kapal Titanic ratusan tahun yang lalu.\n",
    "\n",
    "# Jadi, di dalam dataset ini kita mempunyai target variable/label yaitu Survived. \n",
    "# Semua kolom/fitur lain akan digunakan untuk menentukkan apakah penumpang ini selamat/tidak dari kejadian Titanic.\n",
    "\n",
    "# Data Train digunakan untuk melatih model machine learning kita. \n",
    "# Data Test nantinya digunakan untuk menebak akurasi model kita di Kaggle.\n",
    "\n",
    "# Pada bagian ini, akan dijelakan untuk melakukan membaca data dari file csv dan melakukan concat dataframe dengan membuat sebuah fungsi.\n",
    "\n",
    "# 1. Buat Function concat_df digunakan untuk menggabungkan dua dataset/dataframe dari 2 csv menjadi satu dataframe.\n",
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "# 2. Untuk memasukkan csv ke dalam Pandas Dataframe, kita harus menggunakan pd.read_csv()\n",
    "# Data train kita masukkan ke df_train dan Data test kita masukkan ke df_test. df_all adalah gabungan dari kedua dataframe.\n",
    "df_train = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_train.csv')\n",
    "df_test = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/challenge/feature-engineering/titanic_test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "# 3. Kita dapat menamai tiap dataframe dengan memberikan \"name\" untuk masing-masing dataframe dengan cara :\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "# 4. dfs adalah list yang berisi kedua dataframe.\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penjelasan dari dataset\n",
    "\n",
    "# PassengerId adalah id pada row, maka tidak ada pengaruh terhadap target yang dicari\n",
    "# Survived adalah target yang akan diprediksi, nilai 0 = Not Survived dan nilai 1 = Survived\n",
    "# Pclass (Passenger Class) adalah kategori level sosial ekonomi penumpang dengan nilai (1, 2 atau 3):\n",
    "# 1 = Upper Class\n",
    "# 2 = Middle Class\n",
    "# 3 = Lower Class\n",
    "# Name, Sex dan Age merupakan data self-explanatory\n",
    "# SibSp adalah jumlah saudara dari penumpang\n",
    "# Parch adalah jumlah Orang Tua dan anak dari penumpang\n",
    "# Ticket adalah jumlah tiket penumpang\n",
    "# Fare adalah tarif yang di kenakan kepada penumpang\n",
    "# Cabin adalah nomor kabin penumpang\n",
    "# Embarked adalah pelabuhan pemberangkatan ada 3 pelabuhan (C, Q atau S):\n",
    "# C = Cherbourg\n",
    "# Q = Queenstown\n",
    "# S = Southampton"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
